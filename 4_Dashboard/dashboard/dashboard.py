# Dashboard interactif Streamlit pour l'analyse des offres d'emploi Data Science

import os
import pandas as pd
import streamlit as st
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
from sqlalchemy import create_engine
from dotenv import load_dotenv
from streamlit_folium import st_folium
from geopy.geocoders import Nominatim

st.set_page_config(page_title="Dashboard Emploi Data Science", layout="wide")

# === Chargement des variables d'environnement ===
load_dotenv()
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT")
DB_NAME = os.getenv("DB_NAME")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")

# === Connexion Ã  la base de donnÃ©es RDS ===
@st.cache_data(ttl=600)
def load_data():
    try:
        engine = create_engine(f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}")
        df = pd.read_sql("SELECT * FROM jobs", con=engine)
        return df
    except Exception as e:
        st.error("Erreur de connexion Ã  la base RDS : " + str(e))
        return pd.DataFrame()

# === Chargement des donnÃ©es ===
# Nettoyage des valeurs dans la colonne 'source'
def normalize_sources(df):
    df["source"] = df["source"].astype(str).str.strip().str.lower()
    df["source"] = df["source"].replace({
        "ai-jobs.net": "AI Jobs",
        "ai jobs": "AI Jobs",
        "aijobs": "AI Jobs",
        "adzuna": "Adzuna",
        "api adzuna": "Adzuna",
        "pole emploi": "PÃ´le Emploi",
        "pÃ´le emploi": "PÃ´le Emploi",
        "api pole emploi": "PÃ´le Emploi"
    })
    df["source"] = df["source"].str.title()  # Standardiser le casing
    return df
df = normalize_sources(load_data())

# === Sidebar - Roadmap du projet ===
with st.sidebar.expander("ğŸ“† Roadmap du projet", expanded=False):
    st.markdown("""
- âœ… Collecte des donnÃ©es (AI-jobs.net, Adzuna, API PÃ´le Emploi)
- âœ… Nettoyage, normalisation et fusion des jeux de donnÃ©es
- âœ… Stockage sur AWS (PostgreSQL via RDS, fichiers bruts sur S3)
- âœ… CrÃ©ation du notebook dâ€™analyse exploratoire (Seaborn, Matplotlib, Pandas)
- âœ… Conception du dashboard interactif avec Streamlit
- âœ… IntÃ©gration des visualisations dynamiques (Plotly, Folium)
- âœ… Ajout des mÃ©triques, KPIs, visualisations croisÃ©es
- ğŸ”„ Optimisation du design UI (onglets, filtres, layout)
- ğŸ”œ Ajout de filtres dynamiques avancÃ©s & carte interactive
- ğŸš€ Mise en production prÃ©vue (Docker, GitHub Actions, hÃ©bergement Cloud)
""")

    # === Insights dans la sidebar ===
with st.sidebar.expander(" ğŸ“ˆ Insights Important", expanded=False):
    st.markdown("""
---
### Â© Insights clÃ©s
""")
    try:
        df["has_salary"] = df["salary_min"].notnull() & df["salary_max"].notnull()
        st.markdown(f"- ğŸ” **Source dominante** : {df['source'].value_counts().idxmax()}")
        st.markdown(f"- ğŸ’° **Offres avec salaire** : {len(df[df['has_salary']])}")
        st.markdown(f"- ğŸ“Š **Total d'offres** : {len(df)}")
        st.markdown(f"- ğŸ¢ **Entreprises uniques** : {df['company'].nunique()}")
        st.markdown(f"- ğŸŒ **Villes uniques** : {df['location'].nunique()}")
        st.markdown(f"- ğŸ§‘â€ğŸ’» **Poste le + frÃ©quent** : {df['title'].mode()[0]}")
        st.markdown(f"- ğŸ­ **Entreprise la + active** : {df['company'].value_counts().idxmax()}")
        st.markdown(f"- ğŸ’¸ **Salaire max moyen** : {df['salary_max'].dropna().mean():.0f} â‚¬")
        st.markdown(f"- ğŸ’¸ **Salaire min mÃ©dian** : {df['salary_min'].dropna().median():.0f} â‚¬")
        st.markdown(f"- ğŸ“ˆ **% avec salaire** : {df['has_salary'].mean() * 100:.2f}%")
        st.markdown(f"- ğŸ§¾ **Postes uniques** : {df['title'].nunique()}")
    except:
        st.warning("Impossible de gÃ©nÃ©rer les insights.")
    # === Code source GitHub ===
    st.markdown("""
---
### ğŸ“ Code source :
- [Lien GitHub du projet](https://github.com/space9cowboy/Projet_2_AIA01)
""")

if not df.empty:
    df.dropna(subset=["title", "company", "location"], inplace=True)
    df["title"] = df["title"].str.lower().str.strip()
    df["company"] = df["company"].str.strip()
    df["location"] = df["location"].str.strip()

    st.title("ğŸ“Š Dashboard Emploi Data Science")
    st.markdown("Explorez les tendances de recrutement en Data Science en France via les donnÃ©es collectÃ©es.")

     # Onglets
    tab1, tab2, tab3, tab4, tab6, tab7, tab8 = st.tabs([
        "Sources",
        "Localisations",
        "Postes",
        "Salaires",
        "Croisement",
        "Entreprise",
        "A Propos"
    ])

    with tab1:
        st.subheader("ğŸŒ Nombre d'annonces par source")
        source_counts = df["source"].value_counts().reset_index()
        source_counts.columns = ["source", "count"]

        # Bar chart
        fig1 = px.bar(source_counts, x="source", y="count",
                      labels={"source": "Source", "count": "Nombre d'annonces"}, color_discrete_sequence=["#4C78A8"])
        st.plotly_chart(fig1)

        # Pie chart
        fig_pie = px.pie(source_counts, names="source", values="count", title="Origine des offres (API vs Scraping)", hole=0.3)
        st.plotly_chart(fig_pie)

        st.info(f"ğŸ” Les {len(source_counts)} sources affichÃ©es regroupent {source_counts['count'].sum()} offres, soit environ {round(100 * source_counts['count'].sum() / len(df))}% des annonces filtrÃ©es.")
        st.info("â„¹ï¸ Ces graphiques permettent de comparer les canaux de diffusion des annonces collectÃ©es (scraping vs APIs).")

    with tab2:
        st.subheader("ğŸ“ RÃ©partition des offres par ville (Top 15)")
        df_city = df["location"].value_counts().head(30).reset_index()
        df_city.columns = ["city", "count"]
        fig_city = px.bar(df_city, x="city", y="count", title="Top 15 des villes avec le plus d'offres",
                          labels={"city": "Ville", "count": "Nombre d'offres"}, color_discrete_sequence=["#FF6F61"])
        st.plotly_chart(fig_city)
        st.info(f"ğŸ” Les {len(df_city)} premiÃ¨res villes regroupent {df_city['count'].sum()} offres, soit environ {round(100 * df_city['count'].sum() / len(df))}% des annonces filtrÃ©es.")

    with tab3:
        st.subheader("Postes les plus frÃ©quents")
        top_titles = df["title"].value_counts().head(30).reset_index()
        top_titles.columns = ["title", "count"]
        fig3 = px.bar(top_titles, x="count", y="title", orientation="h",
                      labels={"title": "Poste", "count": "Nombre"}, color_discrete_sequence=["#54A24B"])
        st.plotly_chart(fig3)
        st.info("â„¹ï¸ Cette visualisation rÃ©vÃ¨le les mÃ©tiers les plus demandÃ©s (Data Scientist, Analyste, etc.).")
        
        st.subheader("ğŸ“„ RÃ©partition des types de contrats")
        fig_contract, ax_contract = plt.subplots(figsize=(8, 5))
        sns.countplot(data=df, y="contract_type", order=df["contract_type"].value_counts().index, palette="pastel", ax=ax_contract)
        ax_contract.set_title("RÃ©partition des types de contrats")
        ax_contract.set_xlabel("Nombre d'offres")
        st.pyplot(fig_contract)

        total_contracts = df["contract_type"].notna().sum()
        top_contracts = df["contract_type"].value_counts().head(3)
        st.info(f"ğŸ“Š Sur {total_contracts} offres renseignÃ©es, les types de contrats les plus frÃ©quents sont :\n" + \
                "\n".join([f"- {ct}: {count} offres ({count / total_contracts * 100:.1f}%)" for ct, count in top_contracts.items()]))
        
        if "category" in df.columns:
            st.subheader("ğŸ“ RÃ©partition des catÃ©gories d'emploi")
            fig_cat, ax_cat = plt.subplots(figsize=(8, 5))
            df["category"].value_counts().head(10).plot(kind="barh", color="lightgreen", ax=ax_cat)
            ax_cat.set_title("Top 10 des catÃ©gories d'emploi")
            ax_cat.set_xlabel("Nombre d'offres")
            st.pyplot(fig_cat)

        total_cat = df["category"].notna().sum()
        top_cats = df["category"].value_counts().head(3)
        st.info(f"ğŸ“Œ Sur {total_cat} offres catÃ©gorisÃ©es, les plus frÃ©quentes sont :\n" + \
                "\n".join([f"- {cat}: {count} offres ({count / total_cat * 100:.1f}%)" for cat, count in top_cats.items()]))

    with tab4:
        st.subheader("Distribution des salaires")

        if "salary_min" in df.columns and "salary_max" in df.columns:
            fig4 = px.histogram(df, x=df["salary_max"], nbins=30, title="Distribution des salaires max", color_discrete_sequence=["#E45756"])
            st.plotly_chart(fig4)
            st.info("â„¹ï¸ Cette courbe montre la rÃ©partition des salaires max. Elle permet dâ€™identifier les seuils de rÃ©munÃ©ration les plus frÃ©quents.")


            df_salaire = df.dropna(subset=["salary_min", "salary_max"])
            fig_box = px.box(df_salaire, y="salary_max", points="all", title="Distribution des salaires max", color_discrete_sequence=["#59C3C3"])
            st.plotly_chart(fig_box)
            moyenne = int(df_salaire["salary_max"].mean())
            mediane = int(df_salaire["salary_max"].median())
            max_val = int(df_salaire["salary_max"].max())
            st.info(f"ğŸ“Š Salaire max moyen : {moyenne} â‚¬ â€” MÃ©diane : {mediane} â‚¬ â€” Maximum observÃ© : {max_val} â‚¬")
            
            df["has_salary"] = df["salary_min"].notnull() & df["salary_max"].notnull()
            salary_counts = df["has_salary"].value_counts().rename({True: "Avec salaire", False: "Sans salaire"})
            fig7 = px.pie(values=salary_counts.values, names=salary_counts.index, title="PrÃ©sence des salaires dans les offres")
            st.plotly_chart(fig7)
            st.info(f"ğŸ“Š Environ {salary_counts['Avec salaire']} offres ({round(100 * salary_counts['Avec salaire'] / salary_counts.sum(), 1)}%) contiennent une information salariale, contre {salary_counts['Sans salaire']} offres ({round(100 * salary_counts['Sans salaire'] / salary_counts.sum(), 1)}%) sans indication de salaire.")

            
        else:
            st.warning("âš ï¸ Colonne 'salary' non disponible.")
        
        # === Statistiques descriptives sur les salaires ===
        st.subheader("ğŸ“Š Statistiques descriptives sur les salaires")
        if "salary_min" in df.columns and "salary_max" in df.columns:
            desc_min = df["salary_min"].describe()
            desc_max = df["salary_max"].describe()

            st.markdown("**Statistiques sur `salary_min` :**")
            st.markdown(f"- Moyenne : {desc_min['mean']:.2f} â‚¬")
            st.markdown(f"- MÃ©diane : {desc_min['50%']:.2f} â‚¬")
            st.markdown(f"- Min : {desc_min['min']:.2f} â‚¬ â€” Max : {desc_min['max']:.2f} â‚¬")
            st.markdown(f"- Ã‰cart-type : {desc_min['std']:.2f} â‚¬")

            st.markdown("**Statistiques sur `salary_max` :**")
            st.markdown(f"- Moyenne : {desc_max['mean']:.2f} â‚¬")
            st.markdown(f"- MÃ©diane : {desc_max['50%']:.2f} â‚¬")
            st.markdown(f"- Min : {desc_max['min']:.2f} â‚¬ â€” Max : {desc_max['max']:.2f} â‚¬")
            st.markdown(f"- Ã‰cart-type : {desc_max['std']:.2f} â‚¬")
        else:
            st.warning("âš ï¸ Colonnes 'salary_min' ou 'salary_max' manquantes dans le dataset.")


    with tab6:
        st.subheader("ğŸ—ºï¸ Croisement : Localisations vs Postes")
        top_locations = df["location"].value_counts().head(5).index
        top_titles = df["title"].value_counts().head(5).index
        heatmap_data = df[df["location"].isin(top_locations) & df["title"].isin(top_titles)]
        pivot = pd.crosstab(heatmap_data["location"], heatmap_data["title"])
        fig6, ax6 = plt.subplots(figsize=(10, 6))
        sns.heatmap(pivot, annot=True, cmap="YlGnBu", fmt="d", ax=ax6)
        st.pyplot(fig6)

        total_heatmap = pivot.values.sum()
        st.info(
            f"ğŸ” Cette heatmap montre la rÃ©partition croisÃ©e des postes et localisations les plus populaires. "
            f"Au total, **{total_heatmap}** offres concernent les 5 postes et les 5 villes les plus reprÃ©sentÃ©es."
        )

    with tab7:
        st.subheader("ğŸ¢ Entreprises qui recrutent le plus")

        df_company = df["company"].value_counts().head(15).reset_index()
        df_company.columns = ["company", "count"]

        # Exemple 1 : Pie Chart
        fig_pie = px.pie(df_company, names="company", values="count", title="Top 15 des entreprises qui recrutent", hole=0.3)
        st.plotly_chart(fig_pie)

        # Exemple 2 : Bar Chart
        fig_bar = px.bar(df_company, x="company", y="count", title="Volume d'offres par entreprise (Top 15)", color_discrete_sequence=["#33C3F0"])
        st.plotly_chart(fig_bar)

        # Exemple 3 : Histogramme vertical
        fig_hist = px.histogram(df_company, x="company", y="count", title="Histogramme des entreprises actives", color_discrete_sequence=["#FAA43A"])
        st.plotly_chart(fig_hist)

        total_offres = df_company["count"].sum()
        pourcentage = round((total_offres / len(df)) * 100, 1)
        st.info(f"ğŸ” Les 15 entreprises les plus actives reprÃ©sentent {total_offres} offres, soit environ {pourcentage}% des annonces filtrÃ©es.")
        
    with tab8:
        st.header("Ã€ propos du projet")
        st.markdown("""
            **ğŸ¯ Objectif du projet :**  
            Ce dashboard permet de visualiser les donnÃ©es issues dâ€™un pipeline complet de collecte dâ€™offres dâ€™emploi dans la Data (scraping & APIs), transformÃ©es et stockÃ©es sur AWS RDS, puis explorÃ©es avec Python.

            **ğŸ—‚ Sources de donnÃ©es :**  
            - `ai-jobs.net` (scraping avec BeautifulSoup)  
            - `API Adzuna`  
            - `API PÃ´le Emploi`

            **ğŸ”§ Pipeline ETL :**  
            - Scripts de collecte â†’ Nettoyage â†’ Stockage sur PostgreSQL (via SQLAlchemy) et AWS S3

            **ğŸ“ DonnÃ©es stockÃ©es :**  
            - IntitulÃ© (`title`), entreprise, lieu, salaires min/max, type de contrat, date, source

            **ğŸ“Š Analyses intÃ©grÃ©es :**  
            - Volume dâ€™annonces par source / localisation / entreprise / poste  
            - RÃ©partition temporelle des publications  
            - Distribution des salaires et outliers (boxplot, histogrammes)  

            **ğŸŒ Stack utilisÃ©e :**  
            - Python (Streamlit, Pandas, Seaborn, Plotly, SQLAlchemy)  
            - PostgreSQL sur AWS RDS, AWS S3

            **ğŸ“ Code source :**  
            - [Lien GitHub du projet](https://github.com/ton-utilisateur/projet-data-cloud)
            """)
else:
    st.warning("âš ï¸ Impossible de charger les donnÃ©es.")
