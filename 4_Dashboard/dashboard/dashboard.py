import os
import pandas as pd
import streamlit as st
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
from sqlalchemy import create_engine
from dotenv import load_dotenv

# === Chargement des variables d'environnement ===
load_dotenv()
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT")
DB_NAME = os.getenv("DB_NAME")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")

# === Connexion Ã  la base PostgreSQL RDS ===
@st.cache_data
def load_data():
    try:
        engine = create_engine(
            f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
        )
        df = pd.read_sql("SELECT * FROM jobs", con=engine)
        df.dropna(subset=["title", "company", "location"], inplace=True)
        df["title"] = df["title"].str.lower().str.strip()
        df["company"] = df["company"].str.strip()
        df["location"] = df["location"].str.strip()
        return df
    except Exception as e:
        st.error(f"Erreur de connexion Ã  la base de donnÃ©es : {e}")
        return pd.DataFrame()

df = load_data()

# === Interface Streamlit ===
st.title("\U0001F4CA Dashboard interactif - Offres dâ€™emploi Data")

# === Sidebar - Ã€ propos du projet ===
with st.sidebar.expander("\U0001F4D8 Ã€ propos du projet", expanded=False):
    st.markdown("""
**ğŸ¯ Objectif du projet :**  
Ce projet vise Ã  collecter, analyser et visualiser les offres dâ€™emploi dans le domaine de la **Data** Ã  partir de sources en ligne (scraping et API).

**ğŸ—‚ Sources de donnÃ©es :**  
- `ai-jobs.net` (scraping)  
- `Adzuna API`

**ğŸ”§ Pipeline ETL :**  
- Collecte â¡ï¸ Transformation â¡ï¸ Chargement vers AWS RDS

**ğŸ“ DonnÃ©es rÃ©cupÃ©rÃ©es :**
- `title`, `company`, `location`, `salary_min`, `salary_max`, `contract_type`, `source`

**ğŸ“Š Visualisations issues du notebook :**
- Statistiques descriptives sur les salaires
- Boxplots pour dÃ©tection de valeurs extrÃªmes
- Histogrammes et distributions
- CorrÃ©lation entre salaires min / max
- Outliers dÃ©tectÃ©s automatiquement

**ğŸŒ Stack utilisÃ©e :**  
- Python, Streamlit, Pandas, Seaborn, Matplotlib, Plotly  
- PostgreSQL (AWS RDS), AWS S3

**ğŸ“ Code source :**  
- [Lien GitHub du projet](https://github.com/ton-utilisateur/projet-data-cloud)
""")

# === Sidebar - Roadmap du projet ===
with st.sidebar.expander("\U0001F4C6 Roadmap du projet", expanded=False):
    st.markdown("""
- âœ… Collecte des donnÃ©es (AI-jobs.net, Adzuna)
- âœ… Nettoyage et fusion dans jobs_combined.csv
- âœ… Chargement dans PostgreSQL via RDS
- âœ… Visualisations avec Streamlit
- âœ… IntÃ©gration des analyses du notebook (Seaborn, Matplotlib)
- ğŸš€ Automatisation & dÃ©ploiement complet
""")

if df.empty:
    st.warning("Aucune donnÃ©e chargÃ©e.")
    st.stop()

# === Filtres interactifs ===
st.sidebar.header("\U0001F50D Filtres")
ville = st.sidebar.selectbox("\U0001F4CD Ville", options=["Toutes"] + sorted(df["location"].unique().tolist()))
entreprise = st.sidebar.selectbox("\U0001F3E2 Entreprise", options=["Toutes"] + sorted(df["company"].unique().tolist()))

df_filtered = df.copy()
if ville != "Toutes":
    df_filtered = df_filtered[df_filtered["location"] == ville]
if entreprise != "Toutes":
    df_filtered = df_filtered[df_filtered["company"] == entreprise]

# === KPIs ===
st.subheader("\U0001F4C8 Statistiques clÃ©s")
col1, col2, col3 = st.columns(3)
col1.metric("Total offres", len(df_filtered))
col2.metric("Postes uniques", df_filtered["title"].nunique())
col3.metric("Entreprises", df_filtered["company"].nunique())

# === Graphiques ===
st.subheader("\U0001F3D9ï¸ RÃ©partition des offres par ville")
top_cities = df_filtered["location"].value_counts().nlargest(10).reset_index()
top_cities.columns = ["Ville", "Nombre dâ€™offres"]
fig1 = px.bar(top_cities, x="Ville", y="Nombre dâ€™offres", title="Top 10 villes par nombre dâ€™offres")
st.plotly_chart(fig1)

st.subheader("\U0001F4BC Entreprises les plus actives")
top_companies = df_filtered["company"].value_counts().nlargest(10).reset_index()
top_companies.columns = ["Entreprise", "Nombre dâ€™offres"]
fig2 = px.pie(top_companies, names="Entreprise", values="Nombre dâ€™offres", hole=0.4)
st.plotly_chart(fig2)

if "salary_max" in df_filtered.columns and df_filtered["salary_max"].notna().sum() > 0:
    st.subheader("\U0001F4B0 Distribution des salaires max (boxplot)")
    fig3 = px.box(df_filtered, y="salary_max", points="all", title="Boxplot des salaires max")
    st.plotly_chart(fig3)

    st.subheader("\U0001F4C9 Histogramme des salaires max")
    fig4, ax = plt.subplots()
    sns.histplot(df_filtered["salary_max"].dropna(), kde=True, bins=30, ax=ax)
    st.pyplot(fig4)

    st.subheader("\U0001F9EA Valeurs extrÃªmes dÃ©tectÃ©es")
    q3 = df_filtered["salary_max"].quantile(0.75)
    iqr = q3 - df_filtered["salary_max"].quantile(0.25)
    seuil = q3 + 1.5 * iqr
    outliers = df_filtered[df_filtered["salary_max"] > seuil]
    st.dataframe(outliers)

# === Insights ===
st.subheader("\U0001F4AC Quelques insights Ã  retenir")
nb_remote = df_filtered[df_filtered["location"].str.lower().str.contains("remote")].shape[0]
nb_contrats = df_filtered["contract_type"].nunique(dropna=True)
sal_moy = df_filtered["salary_max"].mean()

st.markdown(f"- ğŸŒ **Nombre dâ€™offres en remote** : {nb_remote}")
st.markdown(f"- ğŸ“„ **Types de contrat diffÃ©rents** : {nb_contrats}")
st.markdown(f"- ğŸ’¸ **Salaire max moyen** : {sal_moy:,.2f} â‚¬")

# === Table des donnÃ©es ===
st.subheader("\U0001F4CB AperÃ§u des donnÃ©es")
st.dataframe(df_filtered.head(100))
